# Service Agent: Secure AI Agents with Google ADK

A demonstration project showing how to build secure AI agents that handle sensitive data using encryption strategies and Google's Agent Development Kit (ADK) lifecycle callbacks.

## ğŸ”’ Security-First Approach

This project demonstrates a practical implementation of data protection in AI agents by:

- **Encrypting sensitive data at session creation** to minimize exposure
- **Using ADK lifecycle callbacks** to decrypt data only when tools need raw access
- **Re-encrypting data immediately** after processing to maintain security
- **Isolating LLMs from sensitive information** while preserving functionality

The key insight: LLMs work with encrypted identifiers while tools handle decryption/encryption through strategic callback placement.

## ğŸ—ï¸ Architecture

```
Session Creation â†’ Encrypt user identifiers
       â†“
Agent Context â†’ LLM processes encrypted data  
       â†“
Tool Execution â†’ before_tool_callback decrypts arguments
       â†“
Data Processing â†’ Tools work with raw data
       â†“  
Response â†’ after_tool_callback re-encrypts sensitive fields
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.13+
- [uv](https://github.com/astral-sh/uv) package manager

### Setup

1. **Clone the repository**
   ```bash
   git clone https://github.com/ksankaran/service-agent.git
   cd service-agent
   ```

2. **Create virtual environment**
   ```bash
   uv venv
   ```

3. **Install dependencies**
   ```bash
   uv sync
   ```

4. **Set up encryption key**
   
   Generate a 32-byte encryption key at [https://generate-random.org/encryption-key-generator](https://generate-random.org/encryption-key-generator) and set it as an environment variable:
   
   ```bash
   export ENCRYPTION_KEY="your-32-byte-key-here"
   ```

5. **Run the server**
   ```bash
   uv run server.py
   ```

## ğŸ“ Project Structure

```
service-agent/
â”œâ”€â”€ info-agent/
â”‚   â”œâ”€â”€ agent.py          # Main agent implementation with callbacks
â”‚   â”œâ”€â”€ callbacks.py      # Encryption/decryption callback functions
â”‚   â””â”€â”€ assets/
â”‚       â””â”€â”€ us-500.csv    # Sample user data for testing
â”œâ”€â”€ crypto.py            # Encryption utilities
â”œâ”€â”€ server.py            # Server implementation
â””â”€â”€ README.md
```

## ğŸ”§ Key Components

### Agent Implementation

The core agent uses Google ADK with encryption callbacks:

```python
root_agent = Agent(
  name="info_agent",
  model=LiteLlm(model="gpt-4.1-mini"),
  tools=[get_user_info],
  before_tool_callback=decrypt_before_tool_callback,
  after_tool_callback=encrypt_after_tool_callback
)
```

### Lifecycle Callbacks

- **`before_tool_callback`**: Decrypts sensitive arguments before tool execution
- **`after_tool_callback`**: Re-encrypts sensitive data in tool responses

### Data Flow

1. **Session starts** with encrypted user identifiers
2. **LLM receives** encrypted data in context (never sees raw sensitive info)
3. **Tool calls** trigger automatic decryption via callbacks
4. **Tools process** raw data securely
5. **Responses** get encrypted before returning to LLM

## ğŸ›¡ï¸ Security Benefits

- **Zero Trust LLM**: Language models never access plaintext sensitive data
- **Minimal Exposure**: Data decrypted only during tool execution
- **Compliance Ready**: Encrypted data at rest and in transit
- **Audit Trail**: All encryption/decryption events can be logged
- **Provider Isolation**: External LLM services only see encrypted tokens

## ğŸ§ª Testing

The project includes sample data (US-500 dataset) for testing the encryption flow. When you run the server:

1. User sessions are created with encrypted email identifiers
2. The agent can retrieve user information using encrypted context
3. Tools decrypt data only when needed for database lookups
4. All sensitive information remains encrypted in logs and LLM interactions

## ğŸ“– Learn More

This project was built to demonstrate the security patterns described in the blog post: "Securing Sensitive Data in AI Agents: Encryption Strategies with Google's Agent ADK"

For detailed implementation insights and security considerations, check out the full blog post and explore the callback implementations in the codebase.

## ğŸ¤ Contributing

Contributions are welcome! Feel free to:

- Report issues or security concerns
- Suggest improvements to the encryption patterns
- Add support for additional callback types
- Enhance the demo with more realistic scenarios

## ğŸ“„ License

This project is open source and available under the MIT License.